# Prioritizing Testing Instances to Enhance the Robustness of Object Detection Systems

## 论文解读

### 作者的主要应用思路

直接将模型的检测结果（伪标签）作为基本事实的一部分，并将它们与测试人员的注释部分相结合，以减少测试数据标注预算。

### 什么是test prioritization methods

即测试优先排序方法，以识别值得模型从大型未标注数据集关注的数据

对于输入图像或视频，对象检测模型用矩形框注释它找到的对象，用适当的类别对其进行标记，然后输出置信度

### Background

`问题`：训练和评估目标检测模型（深度神经网络）的计算量要求很大，并且准备带标注的测试需要大量的人工劳动

`目标`:减少测试数据标注预算

### 主要贡献

1. DeepView首先将对象检测结果拆分为实例，然后分别计算实例的定位和分类能力
2. 作者设计了一个测试优先级工具，通过关注可能导致来自大型未标记数据集的模型错误的实例，使测试人员能够提高模型性能。
3. 作者对两种对象检测模型架构和两个常用数据集进行了广泛的实验。

### 模型方法

#### First Stage

1. 调用对象检测模型对输入测试用例进行推理，并将结果划分为实例

#### Second Stage

1. 分析实例集得到更值得人工标注的实例（每个实例会有一个优先级分数$M=L*C$，其中$L$表示Location能力，$C$表示Classification能力）
2. 以降序的方式对实例优先级分数进行排序（排名更高的实例代表模型很难去检测的实例，即更值得被标注）
3. 模型将前$K$（$K$代表标注预算）个实例映射回原图像，并且高亮标记，其余部分为灰色。
4. 测试人员仅需要对这$K$个实例进行修正，其余灰色部分则代表模型在该区域目标检测能力满足需求

> $C = 1 - s$,  其中s表示模型预测类的置信度
>
> $L = IoU(box^v,box^p)$, 其中$box^v$表示模型预测实例的精准位置，$box^p$表示模型视图的定位

### 应用场景

+ 从`模型优化`的角度来看，由于分布漂移和训练样本不足等问题，目标检测系统在训练和部署后仍然需要不断优化，而DeepView可以及时发现模型性能不佳的实例，从而以最低的标注成本实现最大化的性能提升；
+ 从`模型评估`的角度来看，在安全关键的场景中，用户通常更关注目标检测系统是否会对特定类型的错误表现出严重的性能下降，通过DeepView优先向用户暴露模型错误实例，可以更快地发现并修改系统的安全问题

### 复现结果

#### 有效性Effectiveness（COCO数据集）

| model | Threshold |    APFD     | RAUC-500 |
| :---: | :-------: | :---------: | :------: |
|  SSD  |    0.5    | 0.744/0.743 |  36.77   |
|  SSD  |    0.6    | 0.747/0.746 |  36.77   |
|  SSD  |    0.7    | 0.741/0.741 |  29.51   |
| FRCNN |    0.7    | 0.724/0.724 |  74.07   |
| FRCNN |    0.8    | 0.739/0.739 |  62.48   |
| FRCNN |    0.9    | 0.748/0.747 |  44.34   |

> ps. APFD中左侧代表复现结果，右侧表示论文结果；
>
> RAUC-500均为复现结果，论文结果如下图所示；
>
> 复现结果与论文结果一致；

<img src="images/report/image-20240726133712358.png" alt="image-20240726133712358" style="zoom:75%;" />

#### 多样性Diversity

下图为模型SSD（阈值为0.5）在数据集COCO下的多样性曲线左侧图片为复现曲线，右侧图片为原论文曲线；

横坐标表示随优先级测试实例的累积数目，纵坐标表示发现到的错误类型数量；

其中蓝色曲线表示理论值，即多样性最好的情况，红色线表示DeepView的多样性；

复现结果与论文结果相同；

> 错误类型定义：
>
> 形式化定义为Annotation(x) -> Detection(x), 
>
> 具体分成两种判别：
>
> 1. 分类错误：例cat->dog
> 2. 定位错误(IOU<0.5)：例cat->LE，LE表示定位错误

<p align="center">
  <img src="images/report/image-20240726133836731.png" alt="Image 1" width="45%"/>
  <img src="images/report/image-20240726135347245.png" alt="Image 2" width="45%"/>
</p>



#### 可视化

##### 定位错误（左图为deepview预测，右图为真实标注）

<p align="center">
  <img src="images/report/000000567886.jpg" alt="Image 1" width="45%"/>
  <img src="images/report/000000567886_origin.png" alt="Image 2" width="45%"/>
</p>

##### 分类错误（左图为deepview预测，右图为真实标注）

<p align="center">
  <img src="images/report/000000234779.jpg" alt="Image 1" width="45%"/>
  <img src="images/report/000000234779_origin.png" alt="Image 2" width="45%"/>
</p>

#### 展望与改进

1. DeepView的核心是分数矩阵$M=L*C$，因此其可以简单得扩展到3D目标检测领域，对于3D目标检测领域而言，$C$与2D目标检测领域计算保持一致，均为$C=1-s$，即模型识别错误的置信度；对于$L$而言，应当作出适当改变，原本的二维边框需要扩展到三维边框
2. DeepView这篇论文虽然考虑了模型的多样性性能，但是其并没有将错误类型纳入实例优先级的计算过程中，因此我们可以考虑在计算实例优先级时，增加多样性权重。
3. 在考虑错误类型时，模型将cat->dog，cat->book，视为不同的错误类型，但我认为这个错误均源于模型对cat这个目标识别不精准的缘故导致；因此，我们在进行多样性评价时，是否考虑建立一个二级的多样性评价标准，即第一级判定Annotation(x)是否预测准确，二级判定Annotation(x) -> Detection(x)，是否预测准确

